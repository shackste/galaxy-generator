"""
This file provides a function to evaluate the distribution of latent variables from a set of images.
Encoder from VAE has to be trained on similar kinds of images
"""

from functools import partial
from tqdm import tqdm
import numpy as np

import torch
from torch.utils.data import DataLoader

from . import autoencoder
from . import wasserstein
from . import evaluate_cluster_distribution

encoder = autoencoder.Encoder().cuda()
encoder.load()



def evaluate_latent_distribution(models: dict, data_loader_test: DataLoader, data_loader_valid: DataLoader):
    """ evaluate the reduced latent distribution of images generated by several models

    Parameters
    ----------
    models : dict
        contains several models that generate images.
        key: name attributed to model.
        value: class function to create model instance.
           must support loading of pretrained parameters by model.load().
           must have parameter model.dim_z with required dimension of latent vector.
    """
    data_reference = get_latent(data_loader_test)
    data_validation = get_latent(data_loader_valid) # validation set is used to obtain ground truth.
    distribution_evaluation = evaluate_cluster_distribution.DistributionEvaluation(data_reference, 10)
    distribution_evaluation.add("ground truth", data_validation)
    results_wasserstein = {}
    wasser = partial(wasserstein.wasserstein, blur=0.005, scaling=0.95, splits=4)
    results_wasserstein["ground truth"] = wasser(data_validation, data_reference)
    for name, Model in models.items():
        generator = Model().cuda()
        generator.load()
        data_generated = get_latent(image_generator(generator, data_loader_valid, latent_dim=generator.dim_z))
        generator = 0 # free memory
        distribution_evaluation.add(name, data_generated)
        results_wasserstein[name] = wasser(data_generated, data_reference)
    distribution_evaluation.process(False)
    results_clusters = {
        "histograms": distribution_evaluation.histograms,
        "errors": distribution_evaluation.get_errors()
    }
    return results_clusters, results_wasserstein


def get_latent(dataloader, # iterable generator that provides a tuple (images, dummy).
               rescale: bool = True # if True: rescale image from (0,-1) to (-1,1)
               ):
    """ obtain latent vectors for all images in dataloader """
    latent = []
    for images, _ in dataloader:
        images = images.cuda()
        if rescale:
            images = images*2 - 1
        l = encoder(images)[0].detach().cpu().numpy()
        latent.extend(l)
    return np.array(latent)


def image_generator(model, # pytorch generator model that takes latent vector and label vector as input
                    dataloader: DataLoader, # dataloader to provide labels for the predicted distribution
                    latent_dim: int = 128, # dimension of latent vector required by model
                    ):
    for _, labels in tqdm(dataloader, desc=f"generate images {type(model).__name__}"):
        latent = torch.randn(data_loader_valid.batch_size, latent_dim, device="cuda")
        images = model(latent, labels.cuda())
        yield images, 0


if __name__ == '__main__':
    from ...big import BigGAN2 as BigGAN
    from .. import dataset

    batch_size = 64
    num_workers = 4

    make_data_loader = dataset.MakeDataLoader(augmented=False)
    data_loader_test = make_data_loader.get_data_loader_test(batch_size=batch_size, shuffle=False,
                                                             num_workers=num_workers, drop_last=True)
    data_loader_valid = make_data_loader.get_data_loader_valid(batch_size=batch_size, shuffle=False,
                                                               num_workers=num_workers, drop_last=True)
    models = {"BigGAN":BigGAN.Generator}
    print(evaluate_latent_distribution(models, data_loader_test, data_loader_valid))