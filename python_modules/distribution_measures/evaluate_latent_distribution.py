from functools import partial

from dataset import MakeDataLoader
from sampler import generate_latent
from big.BigGAN2 import Generoter as GeneratorBigGAN
from distribution_measures.encoder import Encoder5  # this is from reduction VAE !!! add actual file
from distribution_measures.wasserstein import wasserstein
from distribution_measures.evaluate_cluster_distribution import DistributionEvaluation

encoder = Encoder5().cuda()
encoder.load()

batch_size = 64
num_workers = 4

make_data_loader = MakeDataLoader(augmented=False)
data_loader_test = make_data_loader.get_data_loader_test(batch_size=batch_size, shuffle=False,
                                                           num_workers=num_workers, drop_last=True)
data_loader_valid = make_data_loader.get_data_loader_valid(batch_size=batch_size, shuffle=False,
                                                           num_workers=num_workers, drop_last=True)

def evaluate_latent_distribution(models: dict):
    """ evaluate the reduced latent distribution of images generated by several models

    Parameters
    ----------
    models : dict
        contains several models that generate images.
        key: name attributed to model.
        value: class function to create model instance.
           must support loading of pretrained parameters by model.load().
           must have parameter model.dim_z with required dimension of latent vector.
    """
    data_reference = get_latent(data_loader_test)
    data_validation = get_latent(data_loader_valid) # validation set is used to obtain ground truth.
    distribution_evaluation = DistributionEvaluation(data_reference, 10)
    distribution_evaluation.add("ground truth", data_validation)
    results_wasserstein = {}
    wasser = partial(wasserstein, blur=0.005, scaling=0.95, splits=4)
    results_wasserstein["ground truth"] = wasser(data_validation, data_reference)
    for name, Model in models.items():
        generator = Model().cuda
        generator.load()
        data_generated = get_latent(image_generator(generator, latent_dim=generator.dim_z))
        generator = 0 # free memory
        distribution_evaluation.add(name, data_generated)
        results_wasserstein[name] = wasser(data_generated, data_reference)
    distribution_evaluation.process(False)
    results_clusters = {
        "histograms": distribution_evaluation.histograms(),
        "errors": distribution_evaluation.get_errors()
    }
    return results_clusters, results_wasserstein


def get_latent(dataloader, # iterable generator that provides a tuple (images, dummy).
               rescale: bool = True # if True: rescale image from (0,-1) to (-1,1)
               ):
    """ obtain latent vectors for all images in dataloader """
    latent = []
    for images, _ in dataloader:
        images = images.cuda()
        if rescale:
            images = images*2 - 1
        l = encoder(images)[0].detach().cpu().numpy()
        latent.extend(l)
    return np.array(latent)


def image_generator(model, # pytorch generator model that takes latent vector and label vector as input
                    latent_dim: int = 128, # dimension of latent vector required by model
                    batch_size: int = batch_size, # number of samples generated per call
                    ):
    for _, labels in data_loader_valid:
        latent = generate_latent(batch_size, latent_dim, sigma=False, device="cuda")
        images = model(latent, labels.cuda())
        yield images


if __name__ == '__main__':
    models = {"BigGAN":GeneratorBigGAN}
    print(evaluate_latent_distribution(models))