{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"ACGAN_CVAE_pytorch.ipynb","private_outputs":true,"provenance":[],"collapsed_sections":["xF15EJdcS4sz","XJ4i89gkVnDl"]},"kernelspec":{"display_name":"Python 3","name":"python3"},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","metadata":{"id":"view-in-github"},"source":["<a href=\"https://colab.research.google.com/github/shackste/galaxy-generator/blob/separate_py_files/ACGAN_CVAE_pytorch.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"]},{"cell_type":"markdown","metadata":{"id":"ZEiOsqeXFUJk"},"source":["PyTorch implementation of combined Conditional Variable Auto Encoder (CVAE) and Auxiliary-Classifier Generative Adversarial Network (ACGAN)\n","\n","continuation of work by Mohamad Dia"]},{"cell_type":"markdown","metadata":{"id":"OqYSQwo1yU4Q"},"source":["# Environment Setup"]},{"cell_type":"markdown","metadata":{"id":"FiixZLra8_zZ"},"source":["## Modules"]},{"cell_type":"code","metadata":{"id":"n_TbcQTbUyvl"},"source":["!pip install torchviz\n","!pip install wandb -qqq"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"vQjam8HTF3NX"},"source":["import sys \n","\n","import matplotlib.pyplot as plt\n","from torch import cat, add, ones, zeros\n","\n","## include separate module files\n","#!git clone -b separate_py_files https://github.com/shackste/galaxy-generator.git\n","#sys.path.insert(0,\"/content/galaxy-generator/python_modules/\")\n","\n","from google.colab import drive\n","drive.mount(\"/drive\")\n","\n","sys.path.insert(0,\"/drive/MyDrive/FHNW/galaxy_generator/galaxy-generator/python_modules/\")\n","\n","from parameter import labels_dim, input_size, parameter\n","from file_system import root, folder_results\n","from helpful_functions import summarize, write_generated_galaxy_images_iteration\n","from sampler import make_training_sample_generator\n","from dataset import get_x_train, get_labels_train\n","from loss import loss_discriminator, loss_generator\n","\n","import pipeline\n","from pipeline import VAE, VAEGAN\n","from discriminator import Discriminator4\n","from encoder import Encoder4\n","from decoder import Decoder4\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"ix0m6LRm655P"},"source":["from pdb import set_trace"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"TPiMSZkOg-JG"},"source":["# Track hyperparameter search via [wandb.ai](https://wandb.ai/shackste/galaxy-generator)"]},{"cell_type":"code","metadata":{"id":"nbhdMEZvg-x2"},"source":["track_hyperparameter = False\n","\n","if track_hyperparameter:\n","    import wandb\n","    !wandb login\n","\n","\n","\n","\"\"\"  USAGE\n","### the following has to be adjusted for every training run\n","### since hyperparameters can be changed on the fly, you find this in Training section\n","\n","wandb.init(project=\"galaxy-generator\", # top level identifier\n","           group=\"first\", # second level identifier, to seperate several groups of tests\n","           job_type=\"training\", # third level identifier, organize different jobs like training and evaluation\n","           tags=[\"first\"], # temporary tags to organize different tasks together\n","           name=\"first\", # bottom level identifier, label of graph in UI\n","           config=parameter.return_parameter_dict()  # here we fill the hyperparameters\n",")\n","\n","## to follow evolution of loss or other measures wich epoch, after each iteration use:\n","wandb.log({\"loss\":loss})  ## here we usually pass loss and accuracy measures\n","\n","## after training is done and all measures are written, finalize with\n","wandb.finish()\n","\"\"\"\n"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"xF15EJdcS4sz"},"source":["# basic test Neural Networks\n","check whether the pipeline components work on their own"]},{"cell_type":"code","metadata":{"id":"R9nQvGR3nP2d"},"source":["summarize(Discriminator4)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"rF6t2XHZn28G"},"source":["import numpy as np\n","from torch import rand\n","\n","\n","net = Encoder4()\n","\n","print(np.sum([np.prod(p.size()) for p in net.parameters()]) == 8508656)\n","input_dummy = rand(3, *input_size)\n","label_dummy = rand(3, labels_dim)\n","\n","net(input_dummy, label_dummy)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"TnAFagCuTpgn"},"source":["net = Decoder4()\n","\n","print(np.sum([np.prod(p.size()) for p in net.parameters()]))\n","input_dummy = rand(3, parameter.latent_dim)\n","label_dummy = rand(3, labels_dim)\n","\n","net(input_dummy, label_dummy).shape"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"SoUTAxuN_47Z"},"source":["net = VAE()\n","images_dummy = rand(5,3,64,64).cuda()\n","labels_dummy = rand(5,3).cuda()\n","pred = net(images_dummy, labels_dummy)\n","pred.shape"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"JVoRvJap_402"},"source":["net = VAEGAN()\n","input_dummy = rand(3,3,64,64).cuda()\n","labels_dummy = rand(3,3).cuda()\n","pred = net(input_dummy, labels_dummy)\n","pred.shape, pred[:,0]"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"XJ4i89gkVnDl"},"source":["# Training Data\n","load data from files at google drive"]},{"cell_type":"code","metadata":{"id":"y60D2u2BVmwj"},"source":["x_train = get_x_train()\n","labels_train = get_labels_train()\n","N_samples = x_train.shape[0]"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"aACg2yM0x2ln"},"source":["# Training"]},{"cell_type":"code","metadata":{"id":"Vj-UnIeJx7eU"},"source":["## if you want to change any parameter:\n","parameter.learning_rate = 0.0002\n","## the following can also be changed during runtime\n","parameter.alpha = 1.\n","parameter.beta = 1.\n","parameter.gamma = 1.\n","parameter.delta = 1.\n","parameter.zeta = 1.\n","\n","\n","## start training with fresh, untrained networks\n","pipeline.decoder = Decoder4().cuda()\n","pipeline.encoder = Encoder4().cuda()\n","pipeline.discriminator = Discriminator4().cuda()\n","\n","## if you want to change discriminator, encoder or decoder network:\n","#pipeline.decoder = YourDecoder().cuda()\n","## before you create the VAE and VAEGAN\n","\n","if track_hyperparameter:\n","    wandb.init(project=\"galaxy-generator\", # top level identifier\n","            group=\"check_losses\", # second level identifier, to seperate several groups of tests\n","            job_type=\"training\", # third level identifier, organize different jobs like training and evaluation\n","            tags=[\"all one\"], # temporary tags to organize different tasks together\n","            name=f\"no class loss, delta=0\", # bottom level identifier, label of graph in UI\n","            config=parameter.return_parameter_dict()  # here we fill the hyperparameters\n","    )\n","\n","\n","\n","\n","epochs = 20\n","batch_size = 128\n","steps = N_samples // batch_size\n","save_interval = 200\n","\n","discriminator_losses = []\n","discriminator_losses_real = []\n","discriminator_losses_fake = []\n","generator_losses = []\n","\n","valid = ones((batch_size,1)).cuda()\n","fake = zeros((batch_size,1)).cuda()\n","\n","vae = VAE()\n","vaegan = VAEGAN()\n","\n","iteration = 0\n","epoch = 0\n","step = 0\n","\n","\n","\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"bDiXsx8Mxfti"},"source":["def training_step():\n","    global iteration\n","    global sample_generator\n","    images, labels = next(sample_generator)\n","\n","    # -------------------\n","    # Train Discriminator\n","    # -------------------\n","    vae.train(False)\n","    pipeline.discriminator.train(True)\n","    pipeline.discriminator.zero_grad()\n","\n","    generated_images = vae(images, labels)\n","    target_real = cat((valid,labels), dim=1)\n","    prediction_real = pipeline.discriminator(images)[:,:1+labels_dim]\n","    target_fake = cat((fake, labels), dim=1)\n","    prediction_fake = pipeline.discriminator(generated_images)[:,:1+labels_dim]\n","\n","    d_loss_real = loss_discriminator(target_real, prediction_real)\n","    d_loss_fake = loss_discriminator(target_fake, prediction_fake)\n","    d_loss = 0.5 * add(d_loss_fake, d_loss_real)\n","    discriminator_losses.append(d_loss)\n","    discriminator_losses_fake.append(d_loss_fake)\n","    discriminator_losses_real.append(d_loss_real)\n","\n","    d_loss_real.backward()\n","    d_loss_fake.backward()\n","    pipeline.discriminator.optimizer.step()\n","\n","    # ---------------\n","    # Train Generator\n","    # ---------------\n","    vae.train(True)\n","    pipeline.discriminator.train(False)\n","    pipeline.encoder.zero_grad()\n","    pipeline.decoder.zero_grad()\n","\n","    generated_images = vae(images, labels)\n","    target = pipeline.discriminator(images)\n","    target[:,0] = 1\n","    target[:,1:1+labels_dim] = labels\n","    target = target.detach()\n","    prediction = pipeline.discriminator(generated_images)\n","    latent = pipeline.encoder(images, labels)\n","\n","    g_loss = loss_generator(target, prediction, images, generated_images, latent)\n","    g_loss.backward()\n","    pipeline.encoder.optimizer.step()\n","    pipeline.decoder.optimizer.step()\n","    generator_losses.append(g_loss)\n","\n","    if track_hyperparameter:\n","        ## save measures to wandb.ai\n","        wandb.log({\"loss discriminator\":d_loss, \"loss generator\":g_loss}) \n","\n","\n","    iteration += 1\n","\n","    print(f\"iteration {iteration}, epoch {epoch+1}, batch {step+1}/{steps},\" + \\\n","          f\"disc_loss {d_loss:.5}, (real {d_loss_real:.5}, fake {d_loss_fake:.5} ) gen_loss {g_loss:.5}\")\n","\n","    if not iteration % save_interval:\n","        write_generated_galaxy_images_iteration(iteration=iteration, images=generated_images.detach().cpu().numpy())\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"u3zDzxauAqqH"},"source":["while epoch < epochs:\n","    sample_generator = make_training_sample_generator(batch_size, x_train, labels_train)\n","    step = 0\n","    while step < steps:\n","        training_step()\n","        step += 1\n","    epoch += 1\n","\n","    # save a plot of the costs\n","    plt.clf()\n","    plt.plot(discriminator_losses, label='discriminator cost')\n","    plt.plot(generator_losses, label='generator cost')\n","    plt.plot(discriminator_losses_fake, label='discriminator cost fake', linestyle=\":\")\n","    plt.plot(discriminator_losses_real, label='discriminator cost real', linestyle=\"-.\")\n","    plt.yscale(\"log\")\n","    plt.legend()\n","    plt.savefig(folder_results+\"cost_vs_iteration.png\")\n","    plt.close()\n","\n","\n","    ### really save?\n","    #pipeline.decoder.save()\n","    #pipeline.encoder.save()\n","    #pipeline.discriminator.save()\n","\n","\n","if track_hyperparameter:\n","    ## after training is done and all measures are written, finalize with\n","    wandb.finish()\n"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"IfBjaXVv7IS0"},"source":["# Testing"]},{"cell_type":"code","metadata":{"id":"tFcJlt6Hh8Qh"},"source":[""],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"NPlmAHXbVZac"},"source":[""],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"gnvpRlGSbVfF"},"source":[""],"execution_count":null,"outputs":[]}]}